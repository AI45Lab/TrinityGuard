# LLM Configuration for Monitor Agents and Judges
# This file configures the LLM settings for safety monitoring components

provider: "openai"
model: "gpt-4o-mini"
api_key: "sk-QsDCIKDroy46jaZfek3NgtihoCI0R4ewufHpwEQqP6EkFvon"
base_url: "http://35.220.164.252:3888/v1/"
temperature: 0
max_tokens: 4096

# Monitor/Judge extended settings
judge_temperature: 0.1      # Temperature for judge analysis (low for consistency)
judge_max_tokens: 500       # Max tokens for judge responses
retry_count: 3              # Number of retries on failure
retry_delay: 1.0            # Delay between retries (seconds)
timeout: 30                 # Request timeout (seconds)

# Optional: Read from environment variable instead
# api_key_env: "OPENAI_API_KEY"
